{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fcfc31-250f-4fa9-a11a-0e33f16a2141",
   "metadata": {},
   "source": [
    "**Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e725d17-5989-4462-9380-848249048b60",
   "metadata": {},
   "source": [
    "**Probability Mass Function (PMF):**\n",
    "\n",
    "The Probability Mass Function (PMF) is a concept used in probability theory to describe the probability distribution of a discrete random variable. It gives the probability that a discrete random variable is exactly equal to some value. Mathematically, for a discrete random variable X, the PMF is denoted by P(X = x), where x is a specific value the random variable can take.\n",
    "\n",
    "For example, consider a fair six-sided die. The PMF for rolling a particular number on the die is:\n",
    "\n",
    "$P(X = x) = \\frac{1}{6}$\n",
    "\n",
    "where X is the random variable representing the outcome of the die roll, and x can be any of the numbers 1 through 6.\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "\n",
    "On the other hand, the Probability Density Function (PDF) is used for continuous random variables. It describes the likelihood of the random variable taking on a particular value within a range. Unlike the PMF, the PDF doesn't directly give probabilities for specific values but rather gives the probability density over a range of values.\n",
    "\n",
    "For example, consider a continuous random variable Y representing the height of people. The PDF might be denoted as f(y), where y is a height value. The probability that Y falls within a certain range [a, b] is given by the integral of the PDF over that range:\n",
    "\n",
    "$P(a \\leq Y \\leq b) = \\int_{a}^{b} f(y) \\,dy $\n",
    "\n",
    "It's important to note that for a continuous random variable, the probability at a specific point is technically zero, and probabilities are defined over intervals.\n",
    "\n",
    "In summary, the PMF is used for discrete random variables, providing the probability of specific values, while the PDF is used for continuous random variables, providing the probability density over a range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1205ca-953d-4cf5-868a-9ec5713359bc",
   "metadata": {},
   "source": [
    "**Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99ba50-bb8d-41fe-acf0-839ae442d9d7",
   "metadata": {},
   "source": [
    "**Cumulative Density Function (CDF):**\n",
    "\n",
    "The Cumulative Density Function (CDF) is a concept used in probability theory to describe the cumulative probability distribution of a random variable. For both discrete and continuous random variables, the CDF gives the probability that the random variable takes on a value less than or equal to a given value.\n",
    "\n",
    "Mathematically, for a random variable X, the CDF is denoted by F(x), and it is defined as:\n",
    "\n",
    "$F(x) = P(X \\leq x)$\n",
    "\n",
    "For a discrete random variable, the CDF is the sum of the probabilities up to a certain value, and for a continuous random variable, it is the integral of the probability density function (PDF) up to a certain value.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let's consider a fair six-sided die again. The CDF for rolling a value less than or equal to x is given by:\n",
    "\n",
    "$F(x) = P(X \\leq x)$\n",
    "\n",
    "For a fair six-sided die, where each outcome is equally likely, the CDF is piecewise constant. For any value \\(x\\) in the range 1 to 6 (inclusive), the CDF is:\n",
    "\n",
    "$F(x) = \\frac{x}{6}$\n",
    "\n",
    "So, for example, if you want to find the probability of rolling a number less than or equal to 3, you would plug in \\(x = 3\\) into the CDF:\n",
    "\n",
    "$F(3) = \\frac{3}{6} = \\frac{1}{2}$\n",
    "\n",
    "**Why CDF is used:**\n",
    "\n",
    "1. **Cumulative Probability:** The CDF provides a way to calculate the cumulative probability of a random variable up to a certain point. It gives the probability that the random variable is less than or equal to a specific value.\n",
    "\n",
    "2. **Ease of Calculation:** In many cases, it's easier to work with cumulative probabilities, especially when dealing with complex distributions. The CDF simplifies the computation of probabilities by avoiding the need to sum or integrate the probability mass or density function for each individual value.\n",
    "\n",
    "3. **Probability Intervals:** The CDF is particularly useful for finding probabilities within intervals. The probability that the random variable falls within a certain range $[a, b]$ is given by $F(b) - F(a)$.\n",
    "\n",
    "In summary, the Cumulative Density Function is a valuable tool in probability theory, providing a convenient way to express and calculate cumulative probabilities for random variables, both discrete and continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145f2ff-7a57-49ed-8b31-2df31d976529",
   "metadata": {},
   "source": [
    "**Q3: What are some examples of situations where the normal distribution might be used as a model?**<br>\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8177e-022a-410e-8564-76a889ce2f88",
   "metadata": {},
   "source": [
    "**Examples of Situations for Normal Distribution:**\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution or bell curve, is commonly used to model various phenomena in fields such as statistics, physics, finance, and natural sciences. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "1. **Height of Individuals:** The distribution of human heights tends to follow a normal distribution.\n",
    "\n",
    "2. **IQ Scores:** IQ scores are often modeled using a normal distribution.\n",
    "\n",
    "3. **Measurement Errors:** Many measurement errors in experimental sciences are assumed to be normally distributed.\n",
    "\n",
    "4. **Financial Returns:** Stock prices and financial returns often exhibit a normal distribution.\n",
    "\n",
    "5. **Blood Pressure:** Blood pressure measurements in a population may be modeled using a normal distribution.\n",
    "\n",
    "6. **Population IQ:** When studying a large population, IQ scores often approximate a normal distribution.\n",
    "\n",
    "**Parameters of the Normal Distribution:**\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean $\\mu$ and the standard deviation $\\sigma$. These parameters play a crucial role in determining the shape of the normal distribution:\n",
    "\n",
    "1. **Mean $\\mu$:** The mean represents the central location of the distribution. It is the point around which the data is symmetrically distributed. Shifting the mean to the right or left moves the entire distribution along the horizontal axis.\n",
    "\n",
    "2. **Standard Deviation $\\sigma$:** The standard deviation measures the spread or dispersion of the distribution. A larger standard deviation results in a wider, more spread-out distribution, while a smaller standard deviation produces a narrower, more concentrated distribution.\n",
    "\n",
    "The probability density function (PDF) of the normal distribution is given by the formula:\n",
    "\n",
    "$f(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "Here, $x$ is a random variable, $\\mu$ is the mean, $\\sigma$ is the standard deviation, $\\pi$ is a mathematical constant (approximately 3.14159), and $e$ is the base of the natural logarithm.\n",
    "\n",
    "In summary, the normal distribution is a versatile model that can represent a wide range of natural phenomena. The mean and standard deviation parameters control the location and spread of the distribution, respectively, influencing its shape and characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ebd986-81bc-49da-b023-ddbde4143144",
   "metadata": {},
   "source": [
    "**Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6e092-9743-4a19-81c2-a39a839a6391",
   "metadata": {},
   "source": [
    "**Importance of Normal Distribution:**\n",
    "\n",
    "The normal distribution is of great importance in various fields due to its mathematical properties and its prevalence in describing the distribution of many natural phenomena. Here are some reasons why the normal distribution is crucial:\n",
    "\n",
    "1. **Statistical Inference:** The normal distribution is fundamental in statistical inference. Many statistical methods and tests, such as hypothesis testing and confidence intervals, assume that the data is approximately normally distributed.\n",
    "\n",
    "2. **Central Limit Theorem:** The Central Limit Theorem states that the sum (or average) of a large number of independent, identically distributed random variables, regardless of their original distribution, will be approximately normally distributed. This theorem underpins the validity of many statistical procedures.\n",
    "\n",
    "3. **Modeling Uncertainty:** In many cases, when there is uncertainty about a quantity or a process, the normal distribution is used to model that uncertainty. This is because of its simplicity and the fact that it arises naturally in various situations.\n",
    "\n",
    "4. **Predictive Modeling:** In predictive modeling and machine learning, assumptions about the distribution of errors or residuals are often based on the normal distribution. Linear regression models, for example, often assume that the residuals are normally distributed.\n",
    "\n",
    "5. **Quality Control:** The normal distribution is frequently used in quality control processes to model variations in manufacturing processes. It helps in setting control limits and identifying outliers.\n",
    "\n",
    "**Real-life Examples of Normal Distribution:**\n",
    "\n",
    "1. **IQ Scores:** Intelligence Quotient (IQ) scores are designed to follow a normal distribution with a mean of 100 and a standard deviation of 15. This distribution allows for the classification of intelligence levels.\n",
    "\n",
    "2. **Height of Individuals:** Human height is often modeled as a normal distribution. While actual height data may deviate slightly from a perfect normal distribution, the approximation is often close enough for practical purposes.\n",
    "\n",
    "3. **Exam Scores:** In educational settings, the distribution of exam scores for a large population of students often approximates a normal distribution. This is particularly true for exams that are well-designed and cover a diverse range of topics.\n",
    "\n",
    "4. **Blood Pressure:** Blood pressure in a population is often modeled using a normal distribution. Normal blood pressure values are centered around a mean value, and deviations from this value are expected to follow a bell-shaped curve.\n",
    "\n",
    "5. **Financial Returns:** In finance, the daily returns of stock prices are often assumed to be normally distributed. This assumption is foundational in various financial models.\n",
    "\n",
    "6. **Error Terms in Regression:** In linear regression models, the errors or residuals are often assumed to be normally distributed. This assumption is important for making statistical inferences and constructing prediction intervals.\n",
    "\n",
    "The normal distribution's ubiquity in various real-world scenarios makes it a valuable tool for statistical analysis and modeling, aiding in making predictions, drawing inferences, and understanding natural variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec736a-4443-455d-a3fa-8992ff430fff",
   "metadata": {},
   "source": [
    "**Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f2dafe-62fe-4fac-9564-4639826da1a6",
   "metadata": {},
   "source": [
    "**Bernoulli Distribution:**\n",
    "\n",
    "The Bernoulli distribution is a discrete probability distribution representing a random variable that can take on one of two possible outcomes, typically labeled as success and failure. It is named after Jacob Bernoulli, a Swiss mathematician. The distribution is characterized by a single parameter, $p$, which is the probability of success.\n",
    "\n",
    "The probability mass function (PMF) of a Bernoulli-distributed random variable is given by:\n",
    "\n",
    "$P(X = k) = \n",
    "  \\begin{cases} \n",
    "    p & \\text{if } k = 1 \\\\\n",
    "    1 - p & \\text{if } k = 0 \n",
    "  \\end{cases}\n",
    "$\n",
    "\n",
    "Here, $X$ is the random variable, $k$ is the outcome (1 for success, 0 for failure), and $p$ is the probability of success.\n",
    "\n",
    "**Example of Bernoulli Distribution:**\n",
    "\n",
    "Consider a single coin flip, where success is defined as getting heads $H$ and failure as getting tails $T$. Let's say the probability of getting heads is $p = 0.5$. The Bernoulli distribution for this scenario is:\n",
    "\n",
    "$P(X = k) = \n",
    "  \\begin{cases} \n",
    "    0.5 & \\text{if } k = 1 \\text{ (heads)} \\\\\n",
    "    0.5 & \\text{if } k = 0 \\text{ (tails)} \n",
    "  \\end{cases}\n",
    "$\n",
    "\n",
    "**Difference between Bernoulli Distribution and Binomial Distribution:**\n",
    "\n",
    "1. **Number of Trials:**\n",
    "   - **Bernoulli Distribution:** Describes a single trial with two possible outcomes (success or failure).\n",
    "   - **Binomial Distribution:** Describes the number of successes in a fixed number of independent and identical Bernoulli trials.\n",
    "\n",
    "2. **Random Variable:**\n",
    "   - **Bernoulli Distribution:** The random variable can only take two values, typically 0 and 1.\n",
    "   - **Binomial Distribution:** The random variable represents the number of successes in a fixed number of trials, and it can take values from 0 to the total number of trials.\n",
    "\n",
    "3. **Parameter:**\n",
    "   - **Bernoulli Distribution:** Characterized by a single parameter $p$, the probability of success in a single trial.\n",
    "   - **Binomial Distribution:** Characterized by two parameters: $n$, the number of trials, and $p$, the probability of success in a single trial.\n",
    "\n",
    "4. **Probability Mass Function (PMF):**\n",
    "   - **Bernoulli Distribution:** $( P(X = k) = p^k (1 - p)^{1-k} ) for (k = 0, 1)$.\n",
    "   - **Binomial Distribution:** $( P(X = k) = \\binom{n}{k} p^k (1 - p)^{n-k} ) for (k = 0, 1, 2, ..., n)$.\n",
    "\n",
    "In summary, the Bernoulli distribution is a special case of the binomial distribution when there is only one trial $n = 1$. The binomial distribution extends the concept to multiple independent and identical trials, allowing the modeling of the number of successes in those trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba7770-4f16-4c5b-ba4f-41b61a9572a0",
   "metadata": {},
   "source": [
    "**Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878cd34b-958e-468b-9046-a5a0d3988177",
   "metadata": {},
   "source": [
    "To find the probability that a randomly selected observation from a normal distribution is greater than a specific value, we can use the Z-score formula and standard normal distribution tables.\n",
    "\n",
    "The Z-score is calculated as follows:\n",
    "\n",
    "$Z = \\frac{(X - \\mu)}{\\sigma}$\n",
    "\n",
    "where:\n",
    "- $X$ is the specific value (in this case, 60),\n",
    "- $\\mu$ is the mean of the distribution (given as 50),\n",
    "- $\\sigma$ is the standard deviation of the distribution (given as 10).\n",
    "\n",
    "Let's calculate the Z-score:\n",
    "\n",
    "$ Z = \\frac{(60 - 50)}{10} = 1 $\n",
    "\n",
    "Now, we look up the corresponding probability from the standard normal distribution table for a Z-score of 1. The standard normal distribution table provides the cumulative probability up to a given Z-score.\n",
    "\n",
    "From the table, the probability corresponding to a Z-score of 1 is approximately 0.8413.\n",
    "\n",
    "So, the probability that a randomly selected observation from the dataset is greater than 60 is approximately 0.8413, or 84.13%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbfc099-f44d-4a88-a601-4782394160aa",
   "metadata": {},
   "source": [
    "**Q7: Explain uniform Distribution with an example.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de7bb1-725c-40e9-9632-6c38e55d2de3",
   "metadata": {},
   "source": [
    "**Uniform Distribution:**\n",
    "\n",
    "The uniform distribution is a probability distribution in which all values within a given range are equally likely to occur. It is characterized by a constant probability density function (PDF) over its entire range. The probability density is uniform, meaning that every possible outcome has the same likelihood of occurring.\n",
    "\n",
    "**Probability Density Function (PDF) of the Uniform Distribution:**\n",
    "\n",
    "For a continuous uniform distribution over the interval $[a, b]$, the PDF is defined as:\n",
    "\n",
    "$ f(x) = \n",
    "  \\begin{cases} \n",
    "    \\frac{1}{b-a} & \\text{for } a \\leq x \\leq b \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$\n",
    "\n",
    "Here, $a$ and $b$ are the parameters defining the interval, and the PDF is flat (constant) over that interval.\n",
    "\n",
    "**Example of Uniform Distribution:**\n",
    "\n",
    "Let's consider an example of a uniform distribution representing the outcome of rolling a fair six-sided die. In this case, the uniform distribution is discrete, as the possible outcomes are integers.\n",
    "\n",
    "For a fair six-sided die, the outcomes are 1, 2, 3, 4, 5, and 6. The probability of each outcome is $ \\frac{1}{6} $ because all outcomes are equally likely.\n",
    "\n",
    "So, the discrete uniform distribution for the die roll is:\n",
    "\n",
    "$ P(X = k) = \n",
    "  \\begin{cases} \n",
    "    \\frac{1}{6} & \\text{for } k = 1, 2, 3, 4, 5, 6 \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$\n",
    "\n",
    "This means that each outcome has an equal probability of $ \\frac{1}{6} $, making it a uniform distribution.\n",
    "\n",
    "In summary, the uniform distribution is characterized by a constant probability over a specific interval, and it is often used to model situations where each outcome within the range has an equal likelihood of occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de333631-12de-48b1-99d6-bfef7188a01a",
   "metadata": {},
   "source": [
    "**Q8: What is the z score? State the importance of the z score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba4fe70-20d4-427e-8251-57b10355e209",
   "metadata": {},
   "source": [
    "**Z-Score:**\n",
    "\n",
    "The Z-score, also known as the standard score or z-value, is a measure of how many standard deviations a particular data point is from the mean of a distribution. It is calculated using the following formula:\n",
    "\n",
    "$ Z = \\frac{(X - \\mu)}{\\sigma} $\n",
    "\n",
    "where:\n",
    "- $ Z $ is the Z-score,\n",
    "- $ X $ is the individual data point,\n",
    "- $ \\mu $ is the mean of the distribution,\n",
    "- $ \\sigma $ is the standard deviation of the distribution.\n",
    "\n",
    "The Z-score indicates whether a data point is typical or unusual in comparison to the rest of the distribution. A positive Z-score means the data point is above the mean, while a negative Z-score means it is below the mean.\n",
    "\n",
    "**Importance of Z-Score:**\n",
    "\n",
    "1. **Standardization:** Z-scores are used to standardize data and make different distributions comparable. By expressing data points in terms of standard deviations from the mean, comparisons can be made across different scales and units.\n",
    "\n",
    "2. **Identifying Outliers:** Z-scores help identify outliers or extreme values in a dataset. Data points with Z-scores significantly different from the mean may be considered outliers.\n",
    "\n",
    "3. **Probability Calculation:** Z-scores are used in probability calculations. In a standard normal distribution (with a mean of 0 and standard deviation of 1), Z-scores correspond to the probabilities of observing values below or above a certain point.\n",
    "\n",
    "4. **Data Analysis and Inference:** Z-scores are widely used in statistical analysis and hypothesis testing. They help in making decisions about sample means and comparing data from different populations.\n",
    "\n",
    "5. **Quality Control:** In manufacturing and quality control processes, Z-scores are used to assess how far a particular measurement is from the expected value, helping identify potential issues.\n",
    "\n",
    "6. **Determination of Percentiles:** Z-scores can be used to determine the percentile rank of a data point within a distribution. This is useful in understanding the relative position of a value in a dataset.\n",
    "\n",
    "7. **Standardizing Scores in Education:** Z-scores are often used in educational assessments to standardize scores across different tests, allowing for a fair comparison of performance.\n",
    "\n",
    "In summary, the Z-score is a valuable statistical tool that provides a standardized measure of a data point's position within a distribution. It aids in comparing and interpreting data, identifying outliers, and making probabilistic assessments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4827c7-2ce3-4f33-845b-d9200203407a",
   "metadata": {},
   "source": [
    "**Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f91bb5-69df-4b15-bac6-cdb3bc85f08e",
   "metadata": {},
   "source": [
    "**Central Limit Theorem (CLT):**\n",
    "\n",
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the shape of the sampling distribution of the sample mean (or sum) for a sufficiently large sample size, regardless of the shape of the original population distribution. It states that, as the sample size increases, the sampling distribution of the sample mean approaches a normal distribution, even if the population distribution is not normal.\n",
    "\n",
    "The Central Limit Theorem is crucial for inferential statistics, hypothesis testing, and confidence interval construction. It is applicable when drawing repeated random samples from a population, making it a powerful tool in statistical analysis.\n",
    "\n",
    "**Statement of the Central Limit Theorem:**\n",
    "\n",
    "Let $X_1, X_2, ..., X_n$ be a random sample of size $n$ drawn from any population with mean $μ$ and standard deviation $σ$. As $n$ becomes large, the sampling distribution of the sample mean $\\bar{X}$ will be approximately normally distributed with mean $μ$ and standard deviation $\\frac{σ}{\\sqrt{n}}$.\n",
    "\n",
    "**Significance of the Central Limit Theorem:**\n",
    "\n",
    "1. **Normality of the Sample Mean Distribution:** The CLT allows us to assume that the sampling distribution of the sample mean is approximately normal, regardless of the shape of the original population distribution. This is particularly powerful because the normal distribution is well understood and has many desirable properties.\n",
    "\n",
    "2. **Statistical Inference:** The CLT is the foundation for many statistical inference procedures. It enables the use of normal distribution-based methods, such as calculating confidence intervals and conducting hypothesis tests, even when dealing with non-normally distributed populations.\n",
    "\n",
    "3. **Large Sample Sizes:** The CLT provides a guideline for when the sample size is considered large enough for normal approximation. As a general rule of thumb, a sample size of 30 or more is often considered sufficient for the CLT to apply.\n",
    "\n",
    "4. **Population Distribution Irrespective:** The CLT is applicable to populations with unknown or non-normal distributions. This makes it a versatile tool for a wide range of applications where the underlying population distribution might not be known.\n",
    "\n",
    "5. **Averages Approach Normality:** The CLT states that the distribution of sample means approaches normality even if the original population distribution is not normal. This holds true for both symmetric and skewed populations.\n",
    "\n",
    "In summary, the Central Limit Theorem is a cornerstone of statistical theory, providing a bridge between the characteristics of a population and the properties of the sample mean distribution. It enables the use of normal distribution-based methods in statistical inference, contributing to the robustness and applicability of statistical techniques in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9211b0-4510-4402-abe6-e1692b05e668",
   "metadata": {},
   "source": [
    "**Q10: State the assumptions of the Central Limit Theorem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0dff6-d54d-4c77-a780-a593cddf4e9c",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a powerful statistical concept, but it relies on certain assumptions to hold true. Here are the key assumptions of the Central Limit Theorem:\n",
    "\n",
    "1. **Random Sampling:** The samples must be drawn randomly from the population. Each individual in the population has an equal chance of being selected in the sample.\n",
    "\n",
    "2. **Independence:** The observations in the sample must be independent of each other. The outcome of one observation should not influence the outcome of another. In the case of sampling without replacement, the sample size should be small relative to the population size to maintain independence.\n",
    "\n",
    "3. **Sample Size:** While the CLT doesn't specify an exact sample size, the sample size should be \"sufficiently large.\" In practice, a commonly used guideline is that a sample size of 30 or more is often considered large enough for the CLT to apply. However, the appropriateness of this rule depends on the nature of the population distribution.\n",
    "\n",
    "4. **Finite Variance:** The population from which the samples are drawn must have a finite variance (\\(σ^2\\)). If the population variance is infinite, the CLT might not hold.\n",
    "\n",
    "5. **Identically Distributed:** The sampled observations should come from an identical distribution. In other words, each observation in the sample should follow the same probability distribution.\n",
    "\n",
    "It's important to note that while the CLT provides an approximation of normality for the distribution of the sample mean, the underlying population distribution can be non-normal. The CLT is particularly robust for larger sample sizes, even when the population distribution is skewed or not well-behaved.\n",
    "\n",
    "Violating these assumptions might lead to biased or unreliable results when relying on the Central Limit Theorem. Understanding and checking these assumptions are crucial when applying statistical methods based on the CLT in practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
