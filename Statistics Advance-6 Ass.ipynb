{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bd34457-1046-4bc7-80b2-f71463f874fe",
   "metadata": {},
   "source": [
    "**Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732aff90-6d51-40d8-b230-67e1f394ce46",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used to compare means across multiple groups. To ensure the validity of ANOVA results, several assumptions must be met. Violations of these assumptions can compromise the reliability of the findings. The key assumptions for ANOVA are:\n",
    "\n",
    "1. **Normality**: The data within each group should follow a normal distribution. This assumption is more robust with larger sample sizes, but severe departures from normality can impact the results. Violations may lead to inaccurate p-values.\n",
    "\n",
    "   *Example Violation:* In a study comparing the effectiveness of different teaching methods, if the scores of one group have a highly skewed distribution, it could violate the normality assumption.\n",
    "\n",
    "2. **Homogeneity of Variances (Homoscedasticity)**: The variances of the groups being compared should be approximately equal. Unequal variances can lead to unequal contributions of each group to the overall ANOVA result.\n",
    "\n",
    "   *Example Violation:* In a drug effectiveness study across different age groups, if the variability of response within the elderly group is much larger than in the younger group, it may violate homogeneity of variances.\n",
    "\n",
    "3. **Independence**: Observations within and between groups should be independent. This means that the data points in one group should not be related to or affect the data points in another group.\n",
    "\n",
    "   *Example Violation:* In a repeated measures design where the same subjects are used in all groups, the assumption of independence is violated. For instance, measuring the blood pressure of the same individuals before and after a treatment in different groups.\n",
    "\n",
    "4. **Random Sampling**: Data should be collected through a random sampling process to ensure that the sample is representative of the population.\n",
    "\n",
    "   *Example Violation:* If a study on the effectiveness of a new medication only includes participants who actively sought out the treatment, it may not be a random sample, potentially biasing the results.\n",
    "\n",
    "If these assumptions are violated, the results of the ANOVA may be unreliable, and alternative analyses or transformations of the data may be necessary. It's essential to assess these assumptions before interpreting ANOVA results and consider using robust techniques if violations are severe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26bdb66-d938-4115-b427-9df5895cd07f",
   "metadata": {},
   "source": [
    "**Q2. What are the three types of ANOVA, and in what situations would each be used?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d181bd3-cfbd-4519-b3b5-53dd0f60acb7",
   "metadata": {},
   "source": [
    "There are three main types of Analysis of Variance (ANOVA), each designed to address different experimental designs and research questions. The three types of ANOVA are:\n",
    "\n",
    "1. **One-Way ANOVA:**\n",
    "   - **Use Case:** One-Way ANOVA is used when there is one independent variable with more than two levels or groups. It helps determine if there are any statistically significant differences among the means of the groups.\n",
    "   - **Example:** Comparing the mean test scores of students who attended three different teaching methods (Group A, Group B, and Group C).\n",
    "\n",
    "2. **Two-Way ANOVA:**\n",
    "   - **Use Case:** Two-Way ANOVA is appropriate when there are two independent variables (factors) and the researcher wants to examine their main effects and interaction effect on the dependent variable.\n",
    "   - **Example:** Investigating the impact of both gender (Male/Female) and treatment (A, B, C) on exam scores. This allows the exploration of whether the effect of treatment differs between genders.\n",
    "\n",
    "3. **Repeated Measures ANOVA:**\n",
    "   - **Use Case:** Repeated Measures ANOVA is used when the same subjects are used for each treatment or measurement, leading to a dependency between observations.\n",
    "   - **Example:** Measuring the blood pressure of individuals before and after three different treatments. The same individuals are measured under all three conditions, and the researcher is interested in whether there are significant differences across the conditions.\n",
    "\n",
    "Each type of ANOVA has its specific applications, and choosing the right one depends on the research design and the nature of the independent variables. It's important to consider the study's design and objectives to determine whether a one-way, two-way, or repeated measures ANOVA is most appropriate for the analysis. Additionally, post hoc tests or pairwise comparisons may be employed to identify specific group differences if the ANOVA indicates overall significant effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025e6d3-57c8-4b3a-9bb8-677df5329b35",
   "metadata": {},
   "source": [
    "**Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4f88e-9151-4df4-b93e-1bec9d532ac0",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) is a crucial concept that helps researchers understand how the total variability in a dataset is distributed among different sources of variation. ANOVA is a statistical method used to compare means across multiple groups and determine if there are significant differences among them.\n",
    "\n",
    "In ANOVA, the total variance observed in the data is decomposed into different components, each attributed to specific sources of variation. There are generally three main components in a one-way ANOVA:\n",
    "\n",
    "1. **Total Variance (TSS - Total Sum of Squares):**\n",
    "   The total variance represents the overall variability in the data without considering any specific factors or groupings. It is the sum of the squared differences between each individual data point and the overall mean.\n",
    "\n",
    "    TSS = \\sum_{i=1}^{N} (Y_i - \\bar{Y})^2 \n",
    "\n",
    "   where $ N $ is the total number of observations, $ Y_i $ is each individual data point, and $ \\bar{Y} $ is the overall mean.\n",
    "\n",
    "2. **Between-Group Variance (BSS - Between-Group Sum of Squares):**\n",
    "   The between-group variance measures the variability among the group means. It is the sum of the squared differences between each group mean and the overall mean, weighted by the number of observations in each group.\n",
    "\n",
    "   $ BSS = \\sum_{j=1}^{k} n_j (\\bar{Y}_j - \\bar{Y})^2 $\n",
    "\n",
    "   where $ k $ is the number of groups, $ n_j $ is the number of observations in the $ j $th group, $ \\bar{Y}_j $ is the mean of the $ j $th group, and $ \\bar{Y} $ is the overall mean.\n",
    "\n",
    "3. **Within-Group Variance (WSS - Within-Group Sum of Squares):**\n",
    "   The within-group variance represents the variability within each group. It is the sum of the squared differences between individual data points and their respective group means.\n",
    "\n",
    "   $ WSS = \\sum_{j=1}^{k} \\sum_{i=1}^{n_j} (Y_{ij} - \\bar{Y}_j)^2 $\n",
    "\n",
    "   where $ Y_{ij} $ is the $ i $th observation in the $ j $th group, $ \\bar{Y}_j $ is the mean of the $ j $th group, and $ n_j $ is the number of observations in the $ j $th group.\n",
    "\n",
    "The total variance (TSS) can be decomposed into the sum of the between-group variance (BSS) and the within-group variance (WSS):\n",
    "\n",
    "$ TSS = BSS + WSS $\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "1. **Hypothesis Testing:** ANOVA helps researchers test whether there are significant differences among group means. By partitioning the variance, researchers can assess whether the observed differences are likely due to real group differences or if they could have occurred by chance.\n",
    "\n",
    "2. **Identifying Sources of Variation:** Researchers can identify and quantify the contribution of different sources of variability in the data. This information is valuable for understanding the factors that influence the observed differences.\n",
    "\n",
    "3. **Model Assessment:** The partitioning of variance allows researchers to evaluate the goodness of fit of the ANOVA model. A large proportion of variance between groups relative to within groups suggests that the group means are different.\n",
    "\n",
    "4. **Effect Size Estimation:** The ratio of between-group variance to total variance (often expressed as eta-squared) provides a measure of effect size, indicating the proportion of total variability attributed to group differences.\n",
    "\n",
    "In summary, understanding the partitioning of variance in ANOVA is essential for making informed interpretations about group differences, assessing the significance of results, and gaining insights into the underlying sources of variability in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ef269-2c3f-4708-a1c2-ae09db501007",
   "metadata": {},
   "source": [
    "**Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf057d0a-8acf-48bf-9c4a-ec81eabaacc3",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the total sum of squares (SST) represents the total variation in the dependent variable. The explained sum of squares (SSE) measures the variation explained by the model or treatment effect, while the residual sum of squares (SSR) measures the unexplained variation or error.\n",
    "\n",
    "Here's how you can calculate SST, SSE, and SSR using Python, assuming you have the necessary data:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "# Assuming you have a DataFrame with a 'group' column representing different treatment groups\n",
    "# and a 'value' column representing the dependent variable.\n",
    "data = {\n",
    "    'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'value': [10, 12, 15, 14, 18, 20]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate overall mean\n",
    "overall_mean = df['value'].mean()\n",
    "\n",
    "# Calculate SST\n",
    "sst = np.sum((df['value'] - overall_mean)**2)\n",
    "\n",
    "# Calculate group means\n",
    "group_means = df.groupby('group')['value'].mean()\n",
    "\n",
    "# Calculate SSE\n",
    "sse = np.sum((df['value'] - df['group'].map(group_means))**2)\n",
    "\n",
    "# Calculate SSR\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "```\n",
    "\n",
    "In this example, we first calculate the overall mean of the dependent variable. Then we compute SST by summing the squared differences between each value and the overall mean. Next, we calculate the group means and use them to compute SSE by summing the squared differences between each value and its corresponding group mean. Finally, SSR is obtained by subtracting SSE from SST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67320ca3-aad4-4254-a058-cab6026faf2a",
   "metadata": {},
   "source": [
    "**Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d84263e-e185-442a-b48f-9439ed99c148",
   "metadata": {},
   "source": [
    "In a two-way ANOVA, there are two factors or independent variables, and you're interested in not only the main effects of each factor but also their interaction effect. Main effects refer to the effect of each individual factor on the dependent variable, while the interaction effect refers to whether the effect of one factor depends on the level of another factor.\n",
    "\n",
    "Here's how you can calculate the main effects and interaction effects using Python:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "# Assuming you have a DataFrame with three columns: 'factor1', 'factor2', and 'value'.\n",
    "data = {\n",
    "    'factor1': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "    'factor2': ['X', 'Y', 'Z', 'X', 'Y', 'Z'],\n",
    "    'value': [10, 12, 15, 14, 18, 20]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('value ~ C(factor1) + C(factor2) + C(factor1):C(factor2)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_factor1 = anova_table.loc['C(factor1)', 'F']\n",
    "main_effect_factor2 = anova_table.loc['C(factor2)', 'F']\n",
    "interaction_effect = anova_table.loc['C(factor1):C(factor2)', 'F']\n",
    "\n",
    "print(\"Main Effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main Effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n",
    "```\n",
    "\n",
    "In this example, we use the `ols` function from `statsmodels` to fit a two-way ANOVA model. The formula `'value ~ C(factor1) + C(factor2) + C(factor1):C(factor2)'` specifies that we are interested in the main effects of `factor1` and `factor2`, as well as their interaction effect. Then we use `sm.stats.anova_lm` to obtain the ANOVA table, which contains the F-statistics for the main effects and interaction effect. Finally, we extract these values from the ANOVA table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4fc62-08da-44c3-81a8-fb647c3ed0e4",
   "metadata": {},
   "source": [
    "**Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c8d6e5-c6c7-45b2-a41d-afe3568c5fe5",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic tests the null hypothesis that the means of all groups are equal against the alternative hypothesis that at least one group mean is different from the others. The p-value associated with the F-statistic indicates the probability of observing the data if the null hypothesis is true. \n",
    "\n",
    "Given the F-statistic of 5.23 and a p-value of 0.02:\n",
    "\n",
    "1. **Conclusion about Differences between Groups**:\n",
    "   - Since the p-value (0.02) is less than the conventional significance level of 0.05, we reject the null hypothesis.\n",
    "   - This indicates that there is sufficient evidence to suggest that at least one group mean is different from the others.\n",
    "\n",
    "2. **Interpretation**:\n",
    "   - The differences in means between groups are statistically significant.\n",
    "   - However, the ANOVA does not tell us which specific group means are different from each other. Additional post-hoc tests (e.g., Tukey's HSD, Bonferroni, etc.) would be needed to determine which specific group(s) differ.\n",
    "   - It's important to consider the practical significance of the differences alongside the statistical significance. Even if differences are statistically significant, they may not be practically significant or meaningful in real-world terms.\n",
    "\n",
    "In summary, based on the given results, we can conclude that there are statistically significant differences between the groups. However, further analysis is required to identify the specific group(s) that differ from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b4f47-c531-4512-b291-f3de22ae6b04",
   "metadata": {},
   "source": [
    "**Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d0f7e-2a8e-4aa9-bd21-894405ef90a5",
   "metadata": {},
   "source": [
    "Handling missing data in repeated measures ANOVA is important to ensure the validity and reliability of the analysis. Here are some common methods for handling missing data:\n",
    "\n",
    "1. **Complete Case Analysis (CCA)**:\n",
    "   - This approach involves analyzing only the cases (participants) with complete data across all time points.\n",
    "   - Potential consequence: It can lead to reduced sample size and potentially biased results if missingness is related to the outcome variable or other important variables.\n",
    "\n",
    "2. **Pairwise Deletion**:\n",
    "   - In this method, missing data are ignored for each pairwise comparison.\n",
    "   - Potential consequence: It can result in loss of statistical power and biased estimates if the missing data are not missing completely at random (MCAR) or missing at random (MAR).\n",
    "\n",
    "3. **Mean Imputation**:\n",
    "   - Missing values are replaced with the mean of the available data for that variable.\n",
    "   - Potential consequence: It can artificially reduce variability and distort relationships between variables, leading to biased estimates and standard errors.\n",
    "\n",
    "4. **Last Observation Carried Forward (LOCF)** or Next Observation Carried Backward (NOCB)**:\n",
    "   - Missing values are replaced with the last observed value (LOCF) or the next observed value (NOCB).\n",
    "   - Potential consequence: It can lead to biased estimates, especially if the missing values are not missing at random or if there is substantial variability over time.\n",
    "\n",
    "5. **Multiple Imputation**:\n",
    "   - This method involves generating multiple plausible values for each missing value based on the observed data and the estimated uncertainty.\n",
    "   - Potential consequence: It provides more accurate estimates and standard errors compared to single imputation methods, but it requires more computational resources and assumptions about the missing data mechanism.\n",
    "\n",
    "6. **Model-Based Imputation**:\n",
    "   - Imputation is based on a statistical model that accounts for the relationships between variables.\n",
    "   - Potential consequence: It can provide more accurate estimates if the model assumptions are met, but it requires careful specification of the imputation model and may not perform well with highly missing data.\n",
    "\n",
    "The choice of method depends on the nature and extent of missing data, the assumptions about the missing data mechanism, and the goals of the analysis. It's important to evaluate the potential consequences of different methods and consider sensitivity analyses to assess the robustness of the results to missing data handling approaches. Additionally, consulting with a statistician or expert in missing data handling can be beneficial for complex analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347da37d-160f-40a6-9dd9-d9074c944902",
   "metadata": {},
   "source": [
    "**Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fb608-74b2-49d1-b018-26029a5661f9",
   "metadata": {},
   "source": [
    "Common post-hoc tests used after ANOVA are designed to compare multiple group means to determine which specific groups differ from each other. Here are some common post-hoc tests and situations where they might be used:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD)**:\n",
    "   - Used when you have equal sample sizes across groups and want to compare all possible pairs of group means.\n",
    "   - Example: In a study comparing the effectiveness of three different teaching methods on student performance, Tukey's HSD can be used to determine which teaching methods result in significantly different outcomes.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - Adjusts the significance level for multiple comparisons to maintain an overall Type I error rate.\n",
    "   - Example: Suppose you're conducting multiple pairwise comparisons between groups in a study with several treatments. You can use Bonferroni correction to reduce the risk of falsely rejecting the null hypothesis due to conducting multiple tests.\n",
    "\n",
    "3. **Scheffé's Test**:\n",
    "   - Used when sample sizes across groups may be unequal and you want to control for the family-wise error rate.\n",
    "   - Example: In a study comparing the effectiveness of different interventions for reducing anxiety levels, Scheffé's test can be used to determine whether any of the interventions produce significantly different outcomes while controlling for the possibility of making a Type I error.\n",
    "\n",
    "4. **Dunnett's Test**:\n",
    "   - Used when you have a control group and want to compare other groups to the control group.\n",
    "   - Example: In a clinical trial comparing the effectiveness of a new drug to a placebo (control group) in reducing blood pressure, Dunnett's test can be used to determine whether the new drug produces a significantly different effect compared to the placebo.\n",
    "\n",
    "5. **Fisher's Least Significant Difference (LSD)**:\n",
    "   - Similar to Tukey's HSD but less conservative; used when sample sizes are equal and variances are homogeneous.\n",
    "   - Example: In an experiment comparing the performance of different brands of fertilizer on plant growth, LSD can be used to identify pairs of fertilizer brands with significantly different effects on plant growth.\n",
    "\n",
    "6. **Games-Howell Test**:\n",
    "   - Used when sample sizes and variances are unequal across groups and you want to conduct all possible pairwise comparisons.\n",
    "   - Example: In a study comparing the effectiveness of various diet plans on weight loss, Games-Howell test can be used to compare the mean weight loss between different diet plans while accounting for the unequal sample sizes and variances.\n",
    "\n",
    "In summary, post-hoc tests are necessary after ANOVA to determine which specific group differences are statistically significant. The choice of post-hoc test depends on the study design, assumptions about the data, and the goals of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841c583-73b0-473c-a755-155a52ba26c8",
   "metadata": {},
   "source": [
    "**Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60278d31-979e-4816-8eb4-c3c304f1537b",
   "metadata": {},
   "source": [
    "To conduct a one-way ANOVA in Python to compare the mean weight loss of three diets (A, B, and C), you can use libraries like NumPy and SciPy. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "# Weight loss data for each diet (A, B, and C)\n",
    "diet_A = [2.5, 3.0, 2.8, 2.9, 2.7, 3.2, 3.5, 2.6, 2.8, 3.1,\n",
    "          2.9, 3.2, 2.7, 2.9, 3.0, 3.1, 2.8, 2.9, 3.4, 3.3,\n",
    "          2.7, 2.8, 3.2, 3.3, 2.6, 2.8, 3.0, 2.9, 3.1, 2.7,\n",
    "          2.9, 2.8, 3.2, 3.4, 2.5, 3.0, 2.7, 3.1, 3.3, 2.8,\n",
    "          2.9, 3.2, 2.6, 2.8, 3.1, 3.3, 2.7, 2.9, 3.0, 3.2]\n",
    "\n",
    "diet_B = [3.1, 2.9, 3.3, 3.4, 2.8, 3.2, 3.1, 3.0, 2.7, 3.5,\n",
    "          3.3, 2.9, 3.1, 2.8, 3.2, 3.4, 3.0, 3.3, 3.1, 3.2,\n",
    "          3.0, 3.5, 3.2, 3.4, 2.9, 3.1, 3.3, 3.2, 2.8, 3.0,\n",
    "          3.4, 3.2, 2.9, 3.1, 3.3, 3.0, 3.2, 3.5, 3.1, 3.4,\n",
    "          2.8, 3.0, 3.2, 3.3, 3.1, 3.4, 3.0, 3.2, 3.1, 3.5]\n",
    "\n",
    "diet_C = [3.8, 3.6, 3.5, 3.7, 3.4, 3.9, 3.6, 3.3, 3.2, 3.7,\n",
    "          3.5, 3.8, 3.3, 3.6, 3.4, 3.9, 3.7, 3.6, 3.4, 3.8,\n",
    "          3.5, 3.9, 3.6, 3.7, 3.4, 3.8, 3.5, 3.6, 3.3, 3.7,\n",
    "          3.6, 3.8, 3.5, 3.9, 3.4, 3.7, 3.6, 3.3, 3.2, 3.8,\n",
    "          3.5, 3.9, 3.6, 3.7, 3.4, 3.8, 3.5, 3.6, 3.3, 3.7]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is significant evidence to suggest that there are differences in mean weight loss between the three diets.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is not enough evidence to suggest that there are differences in mean weight loss between the three diets.\")\n",
    "```\n",
    "\n",
    "This code snippet calculates the F-statistic and p-value for the one-way ANOVA comparing the mean weight loss of the three diets. It then reports the results and provides an interpretation based on the p-value and a chosen significance level (alpha). If the p-value is less than alpha (typically 0.05), we reject the null hypothesis and conclude that there are significant differences in mean weight loss between the diets. Otherwise, we fail to reject the null hypothesis, indicating no significant differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084a9db-f6e1-4ee2-b913-4ee1946d925f",
   "metadata": {},
   "source": [
    "**Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e0f94-b379-4428-a673-12f3ecdbce7a",
   "metadata": {},
   "source": [
    "To conduct a two-way ANOVA in Python to determine if there are any main effects or interaction effects between software programs and employee experience level, you can use libraries like NumPy and SciPy. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Sample data\n",
    "# Generate random data for demonstration purposes\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of employees\n",
    "n = 30\n",
    "\n",
    "# Software programs\n",
    "programs = ['A', 'B', 'C']\n",
    "# Employee experience level\n",
    "experience_levels = ['novice', 'experienced']\n",
    "\n",
    "# Generate random completion times for each combination of program and experience level\n",
    "data = {\n",
    "    'program': np.random.choice(programs, size=n),\n",
    "    'experience_level': np.random.choice(experience_levels, size=n),\n",
    "    'completion_time': np.random.normal(loc=10, scale=2, size=n)  # Mean completion time of 10 with std dev 2\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('completion_time ~ C(program) + C(experience_level) + C(program):C(experience_level)', data=df).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "# Report results\n",
    "print(anova_table)\n",
    "```\n",
    "\n",
    "This code snippet fits a two-way ANOVA model using the `ols` function from `statsmodels` and performs ANOVA using `anova_lm`. The formula `'completion_time ~ C(program) + C(experience_level) + C(program):C(experience_level)'` specifies that we are interested in the main effects of software programs and employee experience levels, as well as their interaction effect. Finally, the results are reported in the ANOVA table, which includes F-statistics and p-values for main effects and interaction effect.\n",
    "\n",
    "Interpretation of the results:\n",
    "- Look for statistically significant p-values (< 0.05) in the ANOVA table to identify significant main effects or interaction effects.\n",
    "- If the p-value for a main effect is significant, it indicates that there is a significant difference in completion time among the levels of that factor (e.g., software programs or experience levels).\n",
    "- If the p-value for the interaction effect is significant, it suggests that the effect of one factor (e.g., software programs) on completion time depends on the levels of another factor (e.g., experience level), or vice versa.\n",
    "- Interpretation should consider both statistical significance and practical significance in the context of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e334b-0026-44d2-a215-a7aac7629cfe",
   "metadata": {},
   "source": [
    "**Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbec96-6a1d-4e85-8848-77c693f90df0",
   "metadata": {},
   "source": [
    "To conduct a two-sample t-test in Python to determine if there are any significant differences in test scores between the control group (traditional teaching method) and the experimental group (new teaching method), you can use libraries like SciPy. If the results are significant, you can follow up with a post-hoc test like Tukey's HSD or Bonferroni correction to determine which group(s) differ significantly from each other. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data\n",
    "# Generate random test scores for demonstration purposes\n",
    "np.random.seed(0)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)  # Control group (traditional teaching method)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100)  # Experimental group (new teaching method)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Report results of t-test\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if results are significant\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference in test scores between the two groups is statistically significant.\")\n",
    "else:\n",
    "    print(\"There is not enough evidence to suggest a significant difference in test scores between the two groups.\")\n",
    "\n",
    "# Follow up with post-hoc test if results are significant\n",
    "if p_value < alpha:\n",
    "    # Combine data for post-hoc test\n",
    "    all_scores = np.concatenate([control_scores, experimental_scores])\n",
    "    group_labels = ['control'] * len(control_scores) + ['experimental'] * len(experimental_scores)\n",
    "\n",
    "    # Perform Tukey's HSD post-hoc test\n",
    "    tukey_results = pairwise_tukeyhsd(all_scores, group_labels, alpha=alpha)\n",
    "\n",
    "    # Report results of post-hoc test\n",
    "    print(\"\\nPost-hoc test results (Tukey's HSD):\")\n",
    "    print(tukey_results)\n",
    "```\n",
    "\n",
    "This code snippet first generates random test scores for the control and experimental groups for demonstration purposes. Then, it performs a two-sample t-test using `stats.ttest_ind` from SciPy to compare the means of the two groups. If the results of the t-test are significant (i.e., the p-value is less than the chosen significance level), it indicates a significant difference in test scores between the groups. In this case, the code proceeds to perform Tukey's HSD post-hoc test using `pairwise_tukeyhsd` from statsmodels to determine which group(s) differ significantly from each other. Finally, the results of the t-test and post-hoc test are reported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5795664-3f53-414e-8530-b8fa72fed283",
   "metadata": {},
   "source": [
    "**Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa127c-f02c-49b2-98cb-bf6dc50977f4",
   "metadata": {},
   "source": [
    "To conduct a repeated measures ANOVA in Python to determine if there are any significant differences in the average daily sales between three retail stores (Store A, Store B, and Store C), you can use libraries like NumPy, pandas, and statsmodels. If the results are significant, you can follow up with a post-hoc test like Tukey's HSD to determine which store(s) differ significantly from each other. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data\n",
    "# Generate random daily sales data for demonstration purposes\n",
    "np.random.seed(0)\n",
    "days = np.arange(1, 31)\n",
    "store_A_sales = np.random.normal(loc=500, scale=50, size=30)  # Sales for Store A\n",
    "store_B_sales = np.random.normal(loc=550, scale=60, size=30)  # Sales for Store B\n",
    "store_C_sales = np.random.normal(loc=600, scale=70, size=30)  # Sales for Store C\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'Day': days,\n",
    "    'Store_A': store_A_sales,\n",
    "    'Store_B': store_B_sales,\n",
    "    'Store_C': store_C_sales\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Melt DataFrame for repeated measures ANOVA\n",
    "melted_df = pd.melt(df, id_vars='Day', var_name='Store', value_name='Sales')\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(melted_df, 'Sales', 'Day', within=['Store']).fit()\n",
    "\n",
    "# Report results of repeated measures ANOVA\n",
    "print(\"Repeated Measures ANOVA results:\")\n",
    "print(rm_anova)\n",
    "\n",
    "# Follow up with post-hoc test if results are significant\n",
    "if rm_anova.anova_table['Pr > F'][0] < 0.05:\n",
    "    # Perform Tukey's HSD post-hoc test\n",
    "    posthoc = pairwise_tukeyhsd(melted_df['Sales'], melted_df['Store'], alpha=0.05)\n",
    "\n",
    "    # Report results of post-hoc test\n",
    "    print(\"\\nPost-hoc test results (Tukey's HSD):\")\n",
    "    print(posthoc)\n",
    "```\n",
    "\n",
    "This code snippet first generates random daily sales data for three retail stores (Store A, Store B, and Store C) for demonstration purposes. Then, it creates a DataFrame and melts it into long format for repeated measures ANOVA using `AnovaRM` from statsmodels. After performing the repeated measures ANOVA, the results are reported. If the p-value of the ANOVA is less than 0.05, indicating a significant difference in sales between the stores, the code proceeds to perform Tukey's HSD post-hoc test using `pairwise_tukeyhsd` from statsmodels. Finally, the results of the post-hoc test are reported."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
